{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Paragraph ranking.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbLGQdvH-WAJ",
        "colab_type": "code",
        "outputId": "46e8c1a2-e53a-44e8-f662-430a929c4320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "from pprint import pprint\n",
        "from nltk.cluster.util import cosine_distance\n",
        "\n",
        "MULTIPLE_WHITESPACE_PATTERN = re.compile(r\"\\s+\", re.UNICODE)\n",
        "nltk.download('punkt')\n",
        "\n",
        "def normalize_whitespace(text):\n",
        "    \"\"\"\n",
        "    Translates multiple whitespace into single space character.\n",
        "    If there is at least one new line character chunk is replaced\n",
        "    by single LF (Unix new line) character.\n",
        "    \"\"\"\n",
        "    return MULTIPLE_WHITESPACE_PATTERN.sub(_replace_whitespace, text)\n",
        "\n",
        "\n",
        "def _replace_whitespace(match):\n",
        "    text = match.group()\n",
        "\n",
        "    if \"\\n\" in text or \"\\r\" in text:\n",
        "        return \"\\n\"\n",
        "    else:\n",
        "        return \" \"\n",
        "\n",
        "\n",
        "def is_blank(string):\n",
        "    \"\"\"\n",
        "    Returns `True` if string contains only white-space characters\n",
        "    or is empty. Otherwise `False` is returned.\n",
        "    \"\"\"\n",
        "    return not string or string.isspace()\n",
        "\n",
        "\n",
        "def get_symmetric_matrix(matrix):\n",
        "    \"\"\"\n",
        "    Get Symmetric matrix\n",
        "    :param matrix:\n",
        "    :return: matrix\n",
        "    \"\"\"\n",
        "    return matrix + matrix.T - np.diag(matrix.diagonal())\n",
        "\n",
        "\n",
        "def core_cosine_similarity(vector1, vector2):\n",
        "    \"\"\"\n",
        "    measure cosine similarity between two vectors\n",
        "    :param vector1:\n",
        "    :param vector2:\n",
        "    :return: 0 < cosine similarity value < 1\n",
        "    \"\"\"\n",
        "    return 1 - cosine_distance(vector1, vector2)\n",
        "\n",
        "\n",
        "'''\n",
        "Note: This is not a summarization algorithm. This Algorithm pics top sentences irrespective of the order they appeared.\n",
        "'''\n",
        "\n",
        "\n",
        "class TextRank4Sentences():\n",
        "    def __init__(self):\n",
        "        self.damping = 0.85  # damping coefficient, usually is .85\n",
        "        self.min_diff = 1e-5  # convergence threshold\n",
        "        self.steps = 100  # iteration steps\n",
        "        self.text_str = None\n",
        "        self.sentences = None\n",
        "        self.pr_vector = None\n",
        "\n",
        "    def _sentence_similarity(self, sent1, sent2, stopwords=None):\n",
        "        if stopwords is None:\n",
        "            stopwords = []\n",
        "\n",
        "        sent1 = [w.lower() for w in sent1]\n",
        "        sent2 = [w.lower() for w in sent2]\n",
        "\n",
        "        all_words = list(set(sent1 + sent2))\n",
        "\n",
        "        vector1 = [0] * len(all_words)\n",
        "        vector2 = [0] * len(all_words)\n",
        "\n",
        "        # build the vector for the first sentence\n",
        "        for w in sent1:\n",
        "            if w in stopwords:\n",
        "                continue\n",
        "            vector1[all_words.index(w)] += 1\n",
        "\n",
        "        # build the vector for the second sentence\n",
        "        for w in sent2:\n",
        "            if w in stopwords:\n",
        "                continue\n",
        "            vector2[all_words.index(w)] += 1\n",
        "\n",
        "        return core_cosine_similarity(vector1, vector2)\n",
        "\n",
        "    def _build_similarity_matrix(self, sentences, stopwords=None):\n",
        "        # create an empty similarity matrix\n",
        "        sm = np.zeros([len(sentences), len(sentences)])\n",
        "\n",
        "        for idx1 in range(len(sentences)):\n",
        "            for idx2 in range(len(sentences)):\n",
        "                if idx1 == idx2:\n",
        "                    continue\n",
        "\n",
        "                sm[idx1][idx2] = self._sentence_similarity(sentences[idx1], sentences[idx2], stopwords=stopwords)\n",
        "\n",
        "        # Get Symmeric matrix\n",
        "        sm = get_symmetric_matrix(sm)\n",
        "\n",
        "        # Normalize matrix by column\n",
        "        norm = np.sum(sm, axis=0)\n",
        "        sm_norm = np.divide(sm, norm, where=norm != 0)  # this is to ignore the 0 element in norm\n",
        "\n",
        "        return sm_norm\n",
        "\n",
        "    def _run_page_rank(self, similarity_matrix):\n",
        "\n",
        "        pr_vector = np.array([1] * len(similarity_matrix))\n",
        "\n",
        "        # Iteration\n",
        "        previous_pr = 0\n",
        "        for epoch in range(self.steps):\n",
        "            pr_vector = (1 - self.damping) + self.damping * np.matmul(similarity_matrix, pr_vector)\n",
        "            if abs(previous_pr - sum(pr_vector)) < self.min_diff:\n",
        "                break\n",
        "            else:\n",
        "                previous_pr = sum(pr_vector)\n",
        "\n",
        "        return pr_vector\n",
        "\n",
        "    def _get_sentence(self, index):\n",
        "\n",
        "        try:\n",
        "            return self.sentences[index]\n",
        "        except IndexError:\n",
        "            return \"\"\n",
        "\n",
        "    def get_top_sentences(self, number=3):\n",
        "\n",
        "        sorted_sent = []\n",
        "        if self.pr_vector is not None:\n",
        "\n",
        "            sorted_pr = np.argsort(self.pr_vector)\n",
        "            sorted_pr = list(sorted_pr)\n",
        "            sorted_pr.reverse()\n",
        "\n",
        "            index = 0\n",
        "            for epoch in range(number):\n",
        "                # print (str(sorted_pr[index]) + \" : \" + str(self.pr_vector[sorted_pr[index]]))\n",
        "                sent = self.sentences[sorted_pr[index]]\n",
        "                sent = normalize_whitespace(sent)\n",
        "                sorted_sent.append([sent,self.pr_vector[sorted_pr[index]]])\n",
        "                index += 1\n",
        "\n",
        "        return sorted_sent\n",
        "\n",
        "    def analyze(self, text, stop_words=None):\n",
        "        self.text_str = text\n",
        "        self.sentences = text.split('\\n\\n')\n",
        "\n",
        "        tokenized_sentences = [word_tokenize(sent) for sent in self.sentences]\n",
        "\n",
        "        similarity_matrix = self._build_similarity_matrix(tokenized_sentences, stop_words)\n",
        "\n",
        "        self.pr_vector = self._run_page_rank(similarity_matrix)\n",
        "        # print(self.pr_vector)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Buky4NYWv8PV",
        "colab_type": "code",
        "outputId": "fc8b2f18-ff32-4a86-f0dd-52884fb53caf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "source": [
        "# read summarized results from file\n",
        "corpusFile=open('summaried-results.txt','r', encoding='utf-8')\n",
        "corpus = corpusFile.read()\n",
        "\n",
        "# converts to lowercase\n",
        "corpus = corpus.lower()\n",
        "\n",
        "sentenceRanker = TextRank4Sentences()\n",
        "sentenceRanker.analyze(corpus)\n",
        "top_sentences = sentenceRanker.get_top_sentences(3)\n",
        "\n",
        "pprint(top_sentences)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['5 questions about semantic seo earlier this month , i attended the '\n",
            "  'semtechbiz2013 conference in san francisco . there was a focus on semantic '\n",
            "  'search and structured data markup at the show , reflecting the expansion of '\n",
            "  'schema.org and google knowledge graph as well as bing snapshots and the '\n",
            "  'growing influence of the open graph protocol . justin briggs wrote a piece '\n",
            "  \"about entity search results that 's over a year old , and it 's still a \"\n",
            "  'useful primer on how search engines are increasingly moving towards these '\n",
            "  \"kinds of results for user queries . however , there 's still not an \"\n",
            "  'agreed-upon term to describe the activities around achieving visibility in '\n",
            "  'the semantic search results or optimizing for a semantic search engine . '\n",
            "  \"what do `` entity-based search results '' look like now ? obviously it 's \"\n",
            "  \"bioshock . ) is structured data markup a ranking factor ? would n't we love \"\n",
            "  'to know ? the serp landscape is a long way from ten blue links ; video and '\n",
            "  'image thumbnails , authorship thumbnails , and rich snippets of many types '\n",
            "  'now fundamentally alter what users click on : it will be interesting to see '\n",
            "  'what testing data and correlation studies tell us about structured data '\n",
            "  'markup as a ranking factor.',\n",
            "  1.0341390888755477],\n",
            " ['every year seo gets more difficult . doing so gives more depth to your '\n",
            "  'content and provides more value . you can figure out these building blocks '\n",
            "  'to create your content using hints google provides within the serps . i use '\n",
            "  'google ’ s keyword planner tool . let ’ s start building from there . what '\n",
            "  'type of problem are you trying to address ? they want to know : what a pex '\n",
            "  'plumbing pipe is . it can even help you rank above position 1 . when you '\n",
            "  'click on the blue links within the field of related searches , they will '\n",
            "  'generate a completely different search results page . the value here is '\n",
            "  'obvious : the post can afford to lose keyword rankings for one of these '\n",
            "  'search queries and still sustain a good amount of its organic traffic in '\n",
            "  'the long run . conclusion offering value , building relevancy , and '\n",
            "  'thinking about the new problems your customers will face is what will '\n",
            "  'separate your post from all the other ones over a longer period of time .',\n",
            "  0.9842806855838173],\n",
            " ['semantic seo is a marketing technique to improve the traffic of a website '\n",
            "  'by providing search engines with metadata and semantically relevant content '\n",
            "  'that can unambiguously answer a specific search intent . in 2011 as google '\n",
            "  'and other search engines began moving towards artificial intelligence and '\n",
            "  'natural language processing to understand the searcher ’ s intent and the '\n",
            "  'meaning of a query they started to work with entities and concepts rather '\n",
            "  'than parsing questions and web pages using keywords . what is seo semantic '\n",
            "  'writing ? learn more about seo semantic writing by watching the free '\n",
            "  'webinar by teodora petkova !',\n",
            "  0.9815802255406354]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}